%load_ext rpy2.ipython
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
import numpy as np

ds = make_classification(random_state=58, n_informative=1, n_redundant=0, n_features=2, n_clusters_per_class=1,
                         class_sep=0.7)
df = pd.DataFrame(ds[0], columns=['first', 'second'])
df['res'] = ds[1]
df.head(15)

df.plot.scatter(x='first', y='second', c='res', colormap='viridis')

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(ds[0], ds[1])

train_df = pd.DataFrame(x_train, columns=['first', 'second'])
train_df['res'] = y_train
train_df.plot.scatter(x='first', y='second', c='res', colormap='viridis')

test_df = pd.DataFrame(x_test, columns=['first', 'second'])
test_df['res'] = y_test
test_df.plot.scatter(x='first', y='second', c='res', colormap='viridis')

def test_KNeighthboursClassifier_hyper(hyperparams):
    for param in hyperparams:
        print(f"param = {param}")
        clf = KNeighborsClassifier(n_neighbors=param)
        show_statistic(clf, x_test, y_test)

test_KNeighthboursClassifier_hyper([1])

from sklearn.naive_bayes import GaussianNB

clf = GaussianNB()
clf.fit(x_train, y_train)
show_statistic(clf, x_test, y_test)

from sklearn.ensemble import RandomForestClassifier

def test_RandomForestClassifier_hyper(hyperparams):
    for param in hyperparams:
        print(f"param = {param}")
        clf = RandomForestClassifier(n_estimators=param)
        clf.fit(x_train, y_train)
        show_statistic(clf, x_test, y_test)
test_RandomForestClassifier_hyper([5])

test_KNeighthboursClassifier_hyper([1, 3, 5, 9])

test_RandomForestClassifier_hyper([5, 10, 15, 20, 50])

